{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from glob import glob\n",
    "import rioxarray as rxr\n",
    "from rioxarray.exceptions import NoDataInBounds\n",
    "import rasterio.features\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from rasterio.errors import NotGeoreferencedWarning\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import importlib.util\n",
    "from rioxarray.merge import merge_arrays\n",
    "from scipy.optimize import minimize\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cv2\n",
    "warnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "def recreate_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "    return path\n",
    "\n",
    "def load_config(path):\n",
    "    spec = importlib.util.spec_from_file_location(\"CFG\", path)\n",
    "    CFG = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(CFG)\n",
    "    return CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/rybna_202203240654\"\n",
    "CFG = load_config(f\"{DATA_DIR}/config.py\").CALIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure logging to file\n",
    "import logging\n",
    "log_path = f\"{DATA_DIR}/logs/calibration_{datetime.now().strftime('%d%m%Y%H%M%S')}.log\"\n",
    "os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "logging.basicConfig(filename=log_path,level=logging.INFO, format='%(asctime)s %(levelname)-8s %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.handlers.clear()\n",
    "#logger.addHandler(logging.StreamHandler())\n",
    "logger.info(\"Starting procedure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/rybna_202203240654/tmp'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMP_DIR = f\"{DATA_DIR}/tmp\"\n",
    "recreate_dir(TMP_DIR)\n",
    "TIFF_DIR = f\"{DATA_DIR}/tiff\"\n",
    "assert os.path.exists(TIFF_DIR), \"tiff_dir does not exist. Please run 1_conversion.ipynb first.\"\n",
    "GEOTIFF_OPTIM_DIR = f\"{DATA_DIR}/geotiff_optim\"\n",
    "assert os.path.exists(GEOTIFF_OPTIM_DIR), \"geotiff_dir does not exist. Please run 1_conversion.ipynb first.\"\n",
    "TIFF_CAL_DIR = f\"{DATA_DIR}/tiff_cal\"\n",
    "GEOTIFF_CAL_DIR = f\"{DATA_DIR}/geotiff_cal\"\n",
    "PLOT_CLIP_DIR = f\"{DATA_DIR}/plot_clip\"\n",
    "PLOT_CAL_DIR = f\"{DATA_DIR}/plot_cal\"\n",
    "TEMP_OPTIM_DATASET_DIR = f\"{DATA_DIR}/temp_optim_dataset\"\n",
    "I_CLIP_DIR = f\"{TEMP_OPTIM_DATASET_DIR}/i_clip\"\n",
    "J_CLIP_DIR = f\"{TEMP_OPTIM_DATASET_DIR}/j_clip\"\n",
    "CLIP_MASK_DIR = f\"{TEMP_OPTIM_DATASET_DIR}/clip_mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [02:16<00:00,  6.50it/s]\n"
     ]
    }
   ],
   "source": [
    "if CFG.CACHE and os.path.exists(f\"{DATA_DIR}/footprints.pkl\"):\n",
    "    logger.info(\"Loading footprints from cache\")\n",
    "    with open(f\"{DATA_DIR}/footprints.pkl\", \"rb\") as f:\n",
    "        footprints = pickle.load(f)\n",
    "else:\n",
    "    logger.info(\"Reading footprints from geotiffs\")\n",
    "    geometries = []\n",
    "    names = []\n",
    "    for path in tqdm(glob(f\"{GEOTIFF_OPTIM_DIR}/*.tiff\")):\n",
    "        raster = rxr.open_rasterio(path)\n",
    "        footprints = rasterio.features.shapes((raster != raster.rio.nodata).values.astype(np.int16), transform=raster.rio.transform())\n",
    "        footprints = [Polygon(geom[\"coordinates\"][0]).simplify(10) for geom, colval in footprints if colval == 1]\n",
    "        assert len(footprints) == 1, \"More than one footprint found\"\n",
    "        names.append(os.path.basename(path))\n",
    "        geometries.append(footprints[0])\n",
    "    footprints = gpd.GeoDataFrame({\"name\": names, \"geometry\": geometries})\n",
    "    #write CRS\n",
    "    footprints.crs = CFG.CRS\n",
    "    with open(f\"{DATA_DIR}/footprints.pkl\", \"wb\") as f:\n",
    "        pickle.dump(footprints, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erode footprints\n",
    "footprints[\"geometry\"] = footprints[\"geometry\"].buffer(-CFG.EROSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_gaussian_filter(arr, sigma):\n",
    "    \"\"\"Apply gaussian filter to array while ignoring nans\"\"\"\n",
    "    V=arr.copy()\n",
    "    V[np.isnan(arr)]=0\n",
    "    VV=gaussian_filter(V,sigma=sigma)\n",
    "    W=0*arr.copy()+1\n",
    "    W[np.isnan(arr)]=0\n",
    "    WW=gaussian_filter(W,sigma=sigma)\n",
    "    Z=VV/WW\n",
    "    Z[np.isnan(arr)]=np.nan\n",
    "    return Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/rybna_202203240654/temp_optim_dataset'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'data/rybna_202203240654/temp_optim_dataset/i_clip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'data/rybna_202203240654/temp_optim_dataset/j_clip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'data/rybna_202203240654/temp_optim_dataset/clip_mask'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 76/890 [15:00<2:40:50, 11.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m j_raster \u001b[39m=\u001b[39m rxr\u001b[39m.\u001b[39mopen_rasterio(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mGEOTIFF_OPTIM_DIR\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mfootprints\u001b[39m.\u001b[39miloc[j][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, masked\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     i_clip \u001b[39m=\u001b[39m i_raster\u001b[39m.\u001b[39;49mrio\u001b[39m.\u001b[39;49mclip([intersection])\n\u001b[1;32m     26\u001b[0m     j_clip \u001b[39m=\u001b[39m j_raster\u001b[39m.\u001b[39mrio\u001b[39m.\u001b[39mclip([intersection])\n\u001b[1;32m     27\u001b[0m \u001b[39mexcept\u001b[39;00m NoDataInBounds:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/rioxarray/raster_array.py:933\u001b[0m, in \u001b[0;36mRasterArray.clip\u001b[0;34m(self, geometries, crs, all_touched, drop, invert, from_disk)\u001b[0m\n\u001b[1;32m    925\u001b[0m     cropped_ds \u001b[39m=\u001b[39m _clip_from_disk(\n\u001b[1;32m    926\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj,\n\u001b[1;32m    927\u001b[0m         geometries\u001b[39m=\u001b[39mgeometries,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    930\u001b[0m         invert\u001b[39m=\u001b[39minvert,\n\u001b[1;32m    931\u001b[0m     )\n\u001b[1;32m    932\u001b[0m \u001b[39mif\u001b[39;00m cropped_ds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 933\u001b[0m     cropped_ds \u001b[39m=\u001b[39m _clip_xarray(\n\u001b[1;32m    934\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj,\n\u001b[1;32m    935\u001b[0m         geometries\u001b[39m=\u001b[39;49mgeometries,\n\u001b[1;32m    936\u001b[0m         all_touched\u001b[39m=\u001b[39;49mall_touched,\n\u001b[1;32m    937\u001b[0m         drop\u001b[39m=\u001b[39;49mdrop,\n\u001b[1;32m    938\u001b[0m         invert\u001b[39m=\u001b[39;49minvert,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[1;32m    941\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    942\u001b[0m     cropped_ds\u001b[39m.\u001b[39mcoords[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_dim]\u001b[39m.\u001b[39msize \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    943\u001b[0m     \u001b[39mor\u001b[39;00m cropped_ds\u001b[39m.\u001b[39mcoords[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_dim]\u001b[39m.\u001b[39msize \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    944\u001b[0m ):\n\u001b[1;32m    945\u001b[0m     \u001b[39mraise\u001b[39;00m NoDataInBounds(\n\u001b[1;32m    946\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo data found in bounds.\u001b[39m\u001b[39m{\u001b[39;00m_get_data_var_message(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    947\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/rioxarray/raster_array.py:238\u001b[0m, in \u001b[0;36m_clip_xarray\u001b[0;34m(xds, geometries, all_touched, drop, invert)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m drop:\n\u001b[1;32m    234\u001b[0m     cropped_ds\u001b[39m.\u001b[39mrio\u001b[39m.\u001b[39mset_spatial_dims(\n\u001b[1;32m    235\u001b[0m         x_dim\u001b[39m=\u001b[39mxds\u001b[39m.\u001b[39mrio\u001b[39m.\u001b[39mx_dim, y_dim\u001b[39m=\u001b[39mxds\u001b[39m.\u001b[39mrio\u001b[39m.\u001b[39my_dim, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    237\u001b[0m     cropped_ds \u001b[39m=\u001b[39m cropped_ds\u001b[39m.\u001b[39mrio\u001b[39m.\u001b[39misel_window(\n\u001b[0;32m--> 238\u001b[0m         rasterio\u001b[39m.\u001b[39;49mwindows\u001b[39m.\u001b[39;49mget_data_window(\n\u001b[1;32m    239\u001b[0m             np\u001b[39m.\u001b[39;49mma\u001b[39m.\u001b[39;49mmasked_array(clip_mask_arr, \u001b[39m~\u001b[39;49mclip_mask_arr)\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m xds\u001b[39m.\u001b[39mrio\u001b[39m.\u001b[39mnodata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misnan(xds\u001b[39m.\u001b[39mrio\u001b[39m.\u001b[39mnodata):\n\u001b[1;32m    243\u001b[0m     cropped_ds \u001b[39m=\u001b[39m cropped_ds\u001b[39m.\u001b[39mfillna(xds\u001b[39m.\u001b[39mrio\u001b[39m.\u001b[39mnodata)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/rasterio/windows.py:168\u001b[0m, in \u001b[0;36mget_data_window\u001b[0;34m(arr, nodata)\u001b[0m\n\u001b[1;32m    166\u001b[0m         arr_mask \u001b[39m=\u001b[39m arr \u001b[39m!=\u001b[39m nodata\n\u001b[1;32m    167\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mis_masked(arr):\n\u001b[0;32m--> 168\u001b[0m     arr_mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39;49mnp\u001b[39m.\u001b[39;49mma\u001b[39m.\u001b[39;49mgetmask(arr)\n\u001b[1;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if CFG.CACHE and os.path.exists(f\"{TEMP_OPTIM_DATASET_DIR}/pairs.pkl\"):\n",
    "    logger.info(\"Loading cached pairs\")\n",
    "    with open(f\"{TEMP_OPTIM_DATASET_DIR}/pairs.pkl\", \"rb\") as f:\n",
    "        pairs_i, pairs_j, pairs_area = pickle.load(f)\n",
    "else:\n",
    "    logger.info(\"Generating temprature global optimization dataset\")\n",
    "    recreate_dir(TEMP_OPTIM_DATASET_DIR)\n",
    "    recreate_dir(I_CLIP_DIR)\n",
    "    recreate_dir(J_CLIP_DIR)\n",
    "    recreate_dir(CLIP_MASK_DIR)\n",
    "    pairs_i = []\n",
    "    pairs_j = []\n",
    "    pairs_area = []\n",
    "    idx = 0\n",
    "    for i in tqdm(range(len(footprints))):\n",
    "        i_raster = rxr.open_rasterio(f\"{GEOTIFF_OPTIM_DIR}/{footprints.iloc[i]['name']}\", masked=True)\n",
    "        for j in range(i+1, len(footprints)):\n",
    "            if footprints.iloc[i].geometry.intersects(footprints.iloc[j].geometry):\n",
    "                intersection = footprints.iloc[i].geometry.intersection(footprints.iloc[j].geometry)\n",
    "                if intersection.area < CFG.MIN_INTERSECTION_AREA:\n",
    "                    logger.info(f\"i ({i}), j ({j}): intersection area too small\")\n",
    "                    continue\n",
    "                j_raster = rxr.open_rasterio(f\"{GEOTIFF_OPTIM_DIR}/{footprints.iloc[j]['name']}\", masked=True)\n",
    "                try:\n",
    "                    i_clip = i_raster.rio.clip([intersection])\n",
    "                    j_clip = j_raster.rio.clip([intersection])\n",
    "                except NoDataInBounds:\n",
    "                    logger.info(f\"i ({i}), j ({j}): NoDataInBounds\")\n",
    "                    continue\n",
    "                j_clip = j_clip.rio.reproject_match(i_clip)\n",
    "                i_clip = i_clip.values[0]\n",
    "                j_clip = j_clip.values[0]\n",
    "                i_clip = nan_gaussian_filter(i_clip, sigma=CFG.GAUSS_SIGMA)\n",
    "                j_clip = nan_gaussian_filter(j_clip, sigma=CFG.GAUSS_SIGMA)\n",
    "                mask = (~np.isnan(i_clip) & ~np.isnan(j_clip)).astype(np.int16)\n",
    "                i_clip[np.isnan(i_clip)] = np.nanmean(i_clip)\n",
    "                j_clip[np.isnan(j_clip)] = np.nanmean(j_clip)\n",
    "                i_clip = cv2.resize(i_clip, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "                j_clip = cv2.resize(j_clip, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "                mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
    "                #assert i_clip, j_clip, mask dont have nans\n",
    "                if np.isnan(i_clip).any():\n",
    "                    logger.info(f\"i ({i}), j ({j}): i_clip has nan\")\n",
    "                    continue\n",
    "                if np.isnan(j_clip).any():\n",
    "                    logger.info(f\"i ({i}), j ({j}): j_clip has nan\")\n",
    "                    continue\n",
    "                if np.isnan(mask).any():\n",
    "                    logger.info(f\"i ({i}), j ({j}): mask has nan\")\n",
    "                    continue\n",
    "                np.save(f\"{I_CLIP_DIR}/{idx}.npy\", i_clip)\n",
    "                np.save(f\"{J_CLIP_DIR}/{idx}.npy\", j_clip)\n",
    "                np.save(f\"{CLIP_MASK_DIR}/{idx}.npy\", mask)\n",
    "                pairs_i.append(i)\n",
    "                pairs_j.append(j)\n",
    "                pairs_area.append(intersection.area)\n",
    "                idx += 1\n",
    "    pairs_i = np.array(pairs_i)\n",
    "    pairs_j = np.array(pairs_j)\n",
    "    pairs_area = np.array(pairs_area)\n",
    "    #pickle dump\n",
    "    with open(f\"{TEMP_OPTIM_DATASET_DIR}/pairs.pkl\", \"wb\") as f:\n",
    "        pickle.dump((pairs_i, pairs_j, pairs_area), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch dataset\n",
    "class TempOptimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, i_clip_dir, j_clip_dir, pairs_i, pairs_j, pairs_area):\n",
    "        self.i_clip_dir = i_clip_dir\n",
    "        self.j_clip_dir = j_clip_dir\n",
    "        self.pairs_i = pairs_i\n",
    "        self.pairs_j = pairs_j\n",
    "        self.pairs_area = pairs_area\n",
    "    def __len__(self):\n",
    "        return len(self.pairs_i)\n",
    "    def __getitem__(self, idx):\n",
    "        i_clip = np.load(f\"{self.i_clip_dir}/{idx}.npy\")\n",
    "        j_clip = np.load(f\"{self.j_clip_dir}/{idx}.npy\")\n",
    "        mask = np.load(f\"{CLIP_MASK_DIR}/{idx}.npy\")\n",
    "        i_clip = torch.tensor(i_clip, dtype=torch.float32)\n",
    "        j_clip = torch.tensor(j_clip, dtype=torch.float32)\n",
    "        mask = torch.tensor(mask, dtype=torch.float32)\n",
    "        i_idx = torch.tensor(self.pairs_i[idx])\n",
    "        j_idx = torch.tensor(self.pairs_j[idx])\n",
    "        area = torch.tensor(self.pairs_area[idx])\n",
    "        #resize to 256x256\n",
    "        return i_idx, j_idx, i_clip, j_clip, mask, area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TempOptimDataset(I_CLIP_DIR, J_CLIP_DIR, pairs_i, pairs_j, pairs_area)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=CFG.NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: nan:  17%|█▋        | 17/101 [03:55<19:24, 13.86s/it]               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CFG = load_config(f\"{DATA_DIR}/config.py\").CALIB\n",
    "n_images = len(footprints)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "a_coefs = torch.ones(n_images, dtype=torch.float32, device=device, requires_grad=True)\n",
    "b_coefs = torch.zeros(n_images, dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.Adam([a_coefs, b_coefs], lr=CFG.LEARNING_RATE)\n",
    "for epoch in range(CFG.EPOCHS):\n",
    "    print(f\"Epoch {epoch}/{CFG.EPOCHS}\")\n",
    "    epoch_losses = []\n",
    "    for i, (i_idx, j_idx, i_clip, j_clip, mask, area) in enumerate(pbar := tqdm(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        #compute loss\n",
    "        i_idx, j_idx, i_clip, j_clip, area = i_idx.to(device), j_idx.to(device), i_clip.to(device), j_clip.to(device), area.to(device)\n",
    "        #add singleton dimension t\n",
    "        i_clip_cal = a_coefs[i_idx][:, None, None] * i_clip + b_coefs[i_idx][:, None, None]\n",
    "        j_clip_cal = a_coefs[j_idx][:, None, None] * j_clip + b_coefs[j_idx][:, None, None]\n",
    "        i_clip_cal_masked = i_clip_cal * mask\n",
    "        j_clip_cal_masked = j_clip_cal * mask\n",
    "        rel_loss = torch.mean(torch.abs(i_clip_cal_masked - j_clip_cal_masked))\n",
    "        abs_loss = 0.0000001*(torch.mean(torch.abs(i_clip_cal_masked - j_clip_cal_masked))+torch.mean(torch.abs(j_clip_cal_masked - j_clip_cal_masked)))\n",
    "        loss = rel_loss + abs_loss\n",
    "        \n",
    "        #print(f\"{loss.item()} = {rel_loss.item()} + {abs_loss.item()}\")\n",
    "        #set pbar description\n",
    "        pbar.set_description(f\"loss: {loss.item()}\")\n",
    "        epoch_losses.append(loss.item())\n",
    "        if torch.isnan(loss):\n",
    "            break\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch loss: {np.mean(epoch_losses)}\")\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_merge(merged_data, new_data, merged_mask, new_mask, index=None, roff=None, coff=None):\n",
    "    merged_data_masked = np.ma.array(merged_data, mask=merged_mask)\n",
    "    merged_data[:] = np.ma.masked_array((merged_data_masked,new_data)).mean(axis=0)\n",
    "rasters = []\n",
    "for path in tqdm(glob(f\"{GEOTIFF_CAL_DIR}/*.tiff\"), desc=\"Loading rasters\"):\n",
    "    rasters.append(rxr.open_rasterio(path, masked=True).copy())\n",
    "print(\"Merging...\")\n",
    "mosaic = merge_arrays(rasters, method=average_merge)\n",
    "mosaic.rio.to_raster(f\"{DATA_DIR}/mosaic_cal.tiff\")\n",
    "print(\"Merging done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
